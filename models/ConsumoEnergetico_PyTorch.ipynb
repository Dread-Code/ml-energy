{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCpwI_3CAK-G"
   },
   "outputs": [],
   "source": [
    "# Energy Forecasting with GRU - Jupyter Notebook Version\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from google.colab import files\n",
    "import psycopg2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'jupyter.dreadcode.dev'\n",
    "port = 5432\n",
    "database = 'postgres'\n",
    "user = 'postgres'\n",
    "password = '5~;X*hLkvdf>xa*T'\n",
    "# Configuración de la conexión\n",
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    database=database,\n",
    "    user=user,\n",
    "    password=password\n",
    ")\n",
    "\n",
    "# Crear un cursor\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Ejecutar consulta para obtener datos de la vista\n",
    "conn.rollback()  # Esto limpia el estado de transacción fallida. Sino una vez falle una consulta se va a quedar pegado.\n",
    "\n",
    "cur.execute('SELECT \"Date\", \"Consumo\" FROM tablasxm_dev.demareal;')\n",
    "\n",
    "datos = cur.fetchall()\n",
    "\n",
    "column_names = [desc[0] for desc in cur.description]\n",
    "df = pd.DataFrame(datos, columns=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzAThI2R9RlE"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "df['Date'] = pd.to_datetime(df['Date'],format='%d/%m/%Y %H:%M')\n",
    "#df['Date'] = pd.to_datetime(df['Date'],format='%d/%m/%Y')\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Hour'] = df['Date'].dt.hour\n",
    "'''\n",
    "\n",
    "features = ['Hour','DayOfWeek','Day','Month','Year']\n",
    "\n",
    "X = df[features]\n",
    "Y = df[['Consumo']]\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_x.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(Y)\n",
    "\n",
    "sequence_length = 24\n",
    "\n",
    "class EnergyDataset(Dataset):\n",
    "    def __init__(self, x, y, seq_len):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        for i in range(len(x) - seq_len):\n",
    "            self.x.append(x[i:i+seq_len])\n",
    "            self.y.append(y[i+seq_len])\n",
    "        self.x = torch.tensor(self.x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Crear datasets\n",
    "dataset = EnergyDataset(X_scaled, y_scaled, sequence_length)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOUt1hcQ-52b"
   },
   "outputs": [],
   "source": [
    "# 🧠 4. Modelo GRU\n",
    "class EnergyGRUModel(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=64, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super(EnergyGRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 64).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model_gru = EnergyGRUModel()\n",
    "criterion_gru = nn.MSELoss()\n",
    "optimizer_gru = torch.optim.Adam(model_gru.parameters(), lr=0.001)\n",
    "\n",
    "'''\n",
    "# 🔁 5. Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        output = model(x_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "'''\n",
    "# 🔁 5. Entrenamiento\n",
    "epochs = 10\n",
    "train_losses_gru = []\n",
    "test_losses_gru = []\n",
    "train_maes_gru = []\n",
    "test_maes_gru = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_gru.train()\n",
    "    epoch_loss = 0\n",
    "    train_predictions = []\n",
    "    train_actuals = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        output = model_gru(x_batch)\n",
    "        loss = criterion_gru(output, y_batch)\n",
    "        optimizer_gru.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_gru.step()\n",
    "        epoch_loss += loss.item()\n",
    "        train_predictions.append(output.detach().numpy())\n",
    "        train_actuals.append(y_batch.detach().numpy())\n",
    "\n",
    "    train_losses_gru.append(epoch_loss/len(train_loader))\n",
    "    train_predictions = scaler_y.inverse_transform(np.vstack(train_predictions))\n",
    "    train_actuals = scaler_y.inverse_transform(np.vstack(train_actuals))\n",
    "    train_mae = mean_absolute_error(train_actuals, train_predictions)\n",
    "    train_maes_gru.append(train_mae)\n",
    "\n",
    "    model_gru.eval()\n",
    "    test_loss = 0\n",
    "    test_predictions = []\n",
    "    test_actuals = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            output = model_gru(x_batch)\n",
    "            loss = criterion_gru(output, y_batch)\n",
    "            test_loss += loss.item()\n",
    "            test_predictions.append(output.numpy())\n",
    "            test_actuals.append(y_batch.numpy())\n",
    "\n",
    "    test_losses_gru.append(test_loss/len(test_loader))\n",
    "    test_predictions = scaler_y.inverse_transform(np.vstack(test_predictions))\n",
    "    test_actuals = scaler_y.inverse_transform(np.vstack(test_actuals))\n",
    "    test_mae = mean_absolute_error(test_actuals, test_predictions)\n",
    "    test_maes_gru.append(test_mae)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses_gru[-1]:.4f}, Test Loss: {test_losses_gru[-1]:.4f}, Train MAE: {train_maes_gru[-1]:.4f}, Test MAE: {test_maes_gru[-1]:.4f}\")\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses_gru, label=\"Training Loss\")\n",
    "plt.plot(test_losses_gru, label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plotting the training and validation MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_maes_gru, label=\"Training MAE\")\n",
    "plt.plot(test_maes_gru, label=\"Validation MAE\")\n",
    "plt.title(\"Training and Validation MAE per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 📊 6. Evaluación\n",
    "model_gru.eval()\n",
    "preds_gru, actuals_gru = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        output = model_gru(x_batch)\n",
    "        preds_gru.append(output.numpy())\n",
    "        actuals_gru.append(y_batch.numpy())\n",
    "\n",
    "preds_gru = scaler_y.inverse_transform(np.vstack(preds_gru))\n",
    "actuals_gru = scaler_y.inverse_transform(np.vstack(actuals_gru))\n",
    "\n",
    "# 📈 7. Visualización\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(actuals_gru[:300], label=\"Real\")\n",
    "plt.plot(preds_gru[:300], label=\"Predicho\")\n",
    "plt.title(\"Consumo energético - Real vs Predicho\")\n",
    "plt.xlabel(\"Tiempos\")\n",
    "plt.ylabel(\"kWh\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calcular métricas\n",
    "mae_gru = mean_absolute_error(actuals_gru, preds_gru)\n",
    "mse_gru = mean_squared_error(actuals_gru, preds_gru)\n",
    "r2_gru = r2_score(actuals_gru, preds_gru)\n",
    "\n",
    "print(f\"MAE: {mae_gru:.4f}\")\n",
    "print(f\"MSE: {mse_gru:.4f}\")\n",
    "print(f\"R2 Score: {r2_gru:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80ev--x3HXMK"
   },
   "outputs": [],
   "source": [
    "# 🧠 4. Modelo LSTM\n",
    "class EnergyLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=64, num_layers=2, output_size=1, dropout=0.2):\n",
    "        super(EnergyLSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 64).to(x.device)\n",
    "        c0 = torch.zeros(2, x.size(0), 64).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model_gru = EnergyLSTMModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model_lstm = EnergyLSTMModel()\n",
    "criterion_lstm = nn.MSELoss()\n",
    "optimizer_lstm = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "\n",
    "'''# 🔁 5. Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model_lstm.train()\n",
    "    epoch_loss = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        output = model_lstm(x_batch)\n",
    "        loss = criterion_lstm(output, y_batch)\n",
    "        optimizer_lstm.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_lstm.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "'''\n",
    "\n",
    "# 🔁 5. Entrenamiento\n",
    "epochs = 10\n",
    "train_losses_lstm = []\n",
    "test_losses_lstm = []\n",
    "train_maes_lstm = []\n",
    "test_maes_lstm = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_lstm.train()\n",
    "    epoch_loss = 0\n",
    "    train_predictions = []\n",
    "    train_actuals = []\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        output = model_lstm(x_batch)\n",
    "        loss = criterion_lstm(output, y_batch)\n",
    "        optimizer_lstm.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_lstm.step()\n",
    "        epoch_loss += loss.item()\n",
    "        train_predictions.append(output.detach().numpy())\n",
    "        train_actuals.append(y_batch.detach().numpy())\n",
    "\n",
    "    train_losses_lstm.append(epoch_loss/len(train_loader))\n",
    "    train_predictions = scaler_y.inverse_transform(np.vstack(train_predictions))\n",
    "    train_actuals = scaler_y.inverse_transform(np.vstack(train_actuals))\n",
    "    train_mae = mean_absolute_error(train_actuals, train_predictions)\n",
    "    train_maes_lstm.append(train_mae)\n",
    "\n",
    "    model_lstm.eval()\n",
    "    test_loss = 0\n",
    "    test_predictions = []\n",
    "    test_actuals = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            output = model_lstm(x_batch)\n",
    "            loss = criterion_lstm(output, y_batch)\n",
    "            test_loss += loss.item()\n",
    "            test_predictions.append(output.numpy())\n",
    "            test_actuals.append(y_batch.numpy())\n",
    "\n",
    "    test_losses_lstm.append(test_loss/len(test_loader))\n",
    "    test_predictions = scaler_y.inverse_transform(np.vstack(test_predictions))\n",
    "    test_actuals = scaler_y.inverse_transform(np.vstack(test_actuals))\n",
    "    test_mae = mean_absolute_error(test_actuals, test_predictions)\n",
    "    test_maes_lstm.append(test_mae)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses_lstm[-1]:.4f}, Test Loss: {test_losses_lstm[-1]:.4f}, Train MAE: {train_maes_lstm[-1]:.4f}, Test MAE: {test_maes_lstm[-1]:.4f}\")\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses_lstm, label=\"Training Loss\")\n",
    "plt.plot(test_losses_lstm, label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss per Epoch (LSTM)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plotting the training and validation MAE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_maes_lstm, label=\"Training MAE\")\n",
    "plt.plot(test_maes_lstm, label=\"Validation MAE\")\n",
    "plt.title(\"Training and Validation MAE per Epoch (LSTM)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 📊 6. Evaluación\n",
    "model_lstm.eval()\n",
    "preds_lstm, actuals_lstm = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        output = model_lstm(x_batch)\n",
    "        preds_lstm.append(output.numpy())\n",
    "        actuals_lstm.append(y_batch.numpy())\n",
    "\n",
    "preds_lstm = scaler_y.inverse_transform(np.vstack(preds_lstm))\n",
    "actuals_lstm = scaler_y.inverse_transform(np.vstack(actuals_lstm))\n",
    "\n",
    "# 📈 7. Visualización\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(actuals_lstm[:300], label=\"Real\")\n",
    "plt.plot(preds_lstm[:300], label=\"Predicho\")\n",
    "plt.title(\"Consumo energético - Real vs Predicho (LSTM)\")\n",
    "plt.xlabel(\"Tiempos\")\n",
    "plt.ylabel(\"kWh\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calcular métricas\n",
    "mae_lstm = mean_absolute_error(actuals_lstm, preds_lstm)\n",
    "mse_lstm = mean_squared_error(actuals_lstm, preds_lstm)\n",
    "r2_lstm = r2_score(actuals_lstm, preds_lstm)\n",
    "\n",
    "print(f\"LSTM MAE: {mae_lstm:.4f}\")\n",
    "print(f\"LSTM MSE: {mse_lstm:.4f}\")\n",
    "print(f\"LSTM R2 Score: {r2_lstm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwdLGP6z-art"
   },
   "outputs": [],
   "source": [
    "# Now save the trained models\n",
    "torch.save(model_gru.state_dict(), 'energy_gru_model.pth')\n",
    "torch.save(model_lstm.state_dict(), 'energy_lstm_model.pth')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
